# Panda Arm

A modular and extensible project for controlling and simulating a Panda robotic arm with perception-driven pick-and-place automation.

---

## ğŸš€ Features

- ROS2-based mission controller  
- Perception-driven pick & place workflow  
- PCL-based 3D clustering and object classification  
- Multi-object mission execution (Laptop, Beer, etc.)  
- Robust filtering, retry loops, and queue-based execution  
- Fully decoupled logic between Perception â†” Control  

---

## ğŸ¯ How the Mission System Works

This project follows a **professional robotics pipeline** using three modules:

1. **Mission Node (Brain)** â€“ Decides what to pick next  
2. **Perception Node (PCL Node)** â€“ Scans and reports all objects  
3. **Execution Node (MoveIt)** â€“ Picks and places the chosen object  

Each mission target (e.g., *Laptop*, *Beer*) is processed in phases.

---

# ğŸŸ¦ **Phase 1: The "Laptop" Mission**

### 1. Mission Control  
Mission list:  
Current target â†’ **Laptop**

### 2. Perception Scan  
Mission node sends a request:

> â€œScan scene for 5 seconds.â€

PCL node returns:

| Object | Label   | Position (x,y,z) |
|--------|----------|------------------|
| A      | Laptop  | (0.4, 0.1, 0.2)  |
| B      | Beer    | (0.3, -0.2, 0.2) |
| C      | Wall    | (1.5, 0.0, 0.0)  |

### 3. Filtering (Brain Logic)

- **Laptop** â†’ matches target, reachable â†’ **added to queue**
- **Beer** â†’ wrong target â†’ ignored
- **Wall** â†’ wrong target + unreachable â†’ ignored

### 4. Execution

- Robot **picks** the Laptop  
- Robot **places** the Laptop  
- Queue empties  
- Robot returns to **Home Pose**  

---

# ğŸŸ¨ **Phase 2: The "Beer" Mission**

Current target â†’ **Beer**

### 1. Perception Scan (Scene Changed)

Laptop is gone. PCL node returns:

| Object | Label | Position |
|--------|--------|----------|
| B      | Beer  | (0.3, -0.2, 0.2) |

### 2. Filtering

- Beer â†’ matches target + reachable â†’ **queued**

### 3. Execution

- Robot **picks** the Beer  
- Robot **places** the Beer  
- Robot returns to **Home Pose**

---

# ğŸŸ© **Phase 3: Mission Complete**

Mission list is empty.  
System prints:

> **â€œAll tasks completed.â€**

---

# ğŸ§  Why This Architecture Is Professional

### âœ” Decoupled Logic  
You can change the mission list from `"Laptop"` to `"Coke"` without changing perception code.

### âœ” Robust Filtering  
Even if camera misdetects objects, the condition  
`if (label != current_target)`  
prevents wrong picks.

### âœ” Stable Motion  
Perception scans for 5 seconds â†’ stops â†’ sends a stable object list.  
Robot does **not** chase jittery real-time detections.

---

## ğŸ› ï¸ Getting Started

Clone the repository:

```bash
git clone https://github.com/yourusername/panda_arm.git
cd panda_arm

ros2 launch panda_description panda_arm_and_sensor.launch.py 

ros2 run my_pcl_processor cloud_tf

ros2 run my_pcl_processor clasification_service_node.py

ros2 run my_pcl_processor feature_extractor_server

ros2 run my_pcl_processor pcl_node
